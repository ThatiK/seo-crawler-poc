# SEO Metadata Crawler â€“ Part 1 (BrightEdge PoC)

This project is a proof-of-concept metadata crawler that can:
- Crawl a single web page
- Extract SEO-relevant metadata (title, description, headings, etc.)
- Classify the page content
- Extract relevant topics
- Serve results via CLI or FastAPI API

## ğŸ§© Architecture

- Language: Python 3.11
- Deployed via: Docker, GitHub Actions, Google Cloud Run
- Uses:
  - `requests`, `BeautifulSoup` for crawling
  - `nltk` for topic extraction
  - `scikit-learn` for optional ML-based classification (enabled via `--use-ml`; otherwise rule-based)
  - `fastapi` for API interface

---

## ğŸ”§ Usage (CLI)

```bash
python src/main/resources/python/main.py \
  --input input.txt \
  --output output.csv \
  --env dev \
  --config-base-path src/main/resources/etc \
  --use-ml
```

- `--input` and `--output`: Can be local or GCS paths (e.g., `gs://...`)
- `--env`: Loads config from `dev.ini` or `prod.ini`
- `--use-ml`: Enables ML-based classifier



## ğŸ¤– Bot User-Agent Setup

This crawler uses a custom bot User-Agent registered for this PoC.  
The implementation and metadata for the bot are maintained in the [project GitHub repository](https://github.com/ThatiK/seo-crawler-poc).

We respect `robots.txt` rules and identify our crawler via:
User-Agent: SEO-Metadata-Crawler/1.0 (+https://thatik.github.io/seo-crawler-poc)

---

## ğŸŒ Usage (API)

Deployed to Cloud Run. Use the `/crawl` endpoint:

### POST `/crawl`

**Request:**
```json
{
  "url": "https://www.example.com",
  "env": "dev",
  "use_ml": false
}
```

**Response:**
```json
{
  "url": "...",
  "title": "...",
  "meta_description": "...",
  "h1": "...",
  "canonical": "...",
  "body": "...",
  "classification": "...",
  "topics": ["...", "..."],
  "error": ""
}
```

**Health check:**
```bash
GET /health
```

---

## ğŸš€ Deployment

1. Dockerized and tested locally using:

```bash
./run_local_api.sh
```

2. CI/CD via GitHub Actions
3. Deploys automatically to Cloud Run using Workload Identity Federation (keyless)

---

## ğŸ“¦ Project Structure

```
src/
â””â”€â”€ main/
    â””â”€â”€ resources/
        â”œâ”€â”€ python/
        â”‚   â”œâ”€â”€ main.py          # CLI batch runner
        â”‚   â”œâ”€â”€ app.py           # FastAPI service
        â”‚   â”œâ”€â”€ crawler_core.py  # Shared crawling logic
        â”‚   â””â”€â”€ ...              # utils, config loader, topic extractor, etc.
        â”œâ”€â”€ etc/
        â”‚   â”œâ”€â”€ dev.ini
        â”‚   â””â”€â”€ prod.ini
```

---

## ğŸ“Œ Example Test URLs

Use these for local or API testing:

- https://www.amazon.com/Cuisinart-CPT-122-Compact-2-Slice-Toaster/dp/B009GQ034C
- https://blog.rei.com/camp/how-to-introduce-your-indoorsy-friend-to-the-outdoors/
- https://www.cnn.com/2013/06/10/politics/edward-snowden-profile/
